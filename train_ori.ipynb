{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO MODELO CHURN\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import auc, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square(df, target, input_cols, threshold):\n",
    "\n",
    "    statistical_significance=[]\n",
    "\n",
    "    for attr in input_cols:\n",
    "        data_count=pd.crosstab(df[attr],df[target])\n",
    "        obs=data_count.values\n",
    "   \n",
    "        chi2, p, dof, expected = chi2_contingency(obs)\n",
    "\n",
    "        statistical_significance.append([attr,np.round(p,4)])\n",
    "\n",
    "    statistical_significance=pd.DataFrame(statistical_significance)\n",
    "    statistical_significance.columns=[\"Attribute\",\"P-value\"]\n",
    "\n",
    "    df_mod_cols = statistical_significance[statistical_significance[\"P-value\"]<threshold].Attribute.tolist() \n",
    "  \n",
    "    return df_mod_cols, statistical_significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_get_auc(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    y_train_prob = model.predict_proba(X_train)\n",
    "    y_test_prob = model.predict_proba(X_test)\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y_train, y_train_prob[:, 1])\n",
    "    print(\"AUC train = \", round(auc(fpr, tpr), 2))\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_test_prob[:, 1])\n",
    "    print(\"AUC test = \", round(auc(fpr, tpr), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tablón entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción dataset con variables input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos datasets de diciembre\n",
    "\n",
    "clientes_diciembre_df = pd.read_csv(\"datos/clientes_2023-12-01.csv\", sep='|')\n",
    "consumos_diciembre_df = pd.read_csv(\"datos/consumos_2023-12-01.csv\", sep='|')\n",
    "financiacion_diciembre_df = pd.read_csv(\"datos/financiacion_2023-12-01.csv\",sep='|')\n",
    "productos_diciembre_df = pd.read_csv(\"datos/productos_2023-12-01.csv\", sep= '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos datasets de diciembre\n",
    "\n",
    "df_diciembre = clientes_diciembre_df.merge(consumos_diciembre_df, on=\"id\", how=\"left\")\n",
    "df_diciembre = df_diciembre.merge(financiacion_diciembre_df, on=\"id\", how=\"left\")\n",
    "df_diciembre = df_diciembre.merge(productos_diciembre_df, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de la columna target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos clientes de enero\n",
    "\n",
    "df_enero = pd.read_csv(\"datos/clientes_2024-01-01.csv\", sep= '|')\n",
    "\n",
    "df_enero['target'] = 0\n",
    "df_enero = df_enero[['id','target']]\n",
    "\n",
    "# Hacemos left join de enero sobre diciembre, para que así aparezcan todos los clientes del dataset de diciembre\n",
    "# Imputamos los NA de target con 1 (clientes que estaban en diciembre pero no en enero -> se han ido de la compañia)\n",
    "\n",
    "df = pd.merge(df_diciembre, df_enero, on = 'id', how='left')\n",
    "df = df.fillna({'target':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id', axis = 1) # las columnas identificadoras no sirven para el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrección de inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy() # creamos una copia para no sobrescribir el df original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2[\"vel_conexion\"] < 0, 'vel_conexion'] = np.nan\n",
    "df2.loc[df2['conexion']=='adsl', 'conexion'] = 'ADSL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.fillna({'descuentos':'NO', 'financiacion':'NO', 'incidencia':'NO'})\n",
    "df2 = df2.fillna({'num_dt':0, 'imp_financ':0})\n",
    "df2 = df2.fillna({'vel_conexion':df2['vel_conexion'].mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversión de categóricas a numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['financiacion'] = np.where(df2['financiacion']==\"SI\", 1, 0)\n",
    "df2['incidencia'] = np.where(df2['incidencia']==\"SI\", 1, 0)\n",
    "df2['descuentos'] = np.where(df2['descuentos']==\"SI\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingeniería de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "año_actual = datetime.now().year\n",
    "df2['antiguedad'] = año_actual - df2['antiguedad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección previa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2[\"target\"]\n",
    "X = df2.drop(columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_significant, statistical_significance = chi_square(df2, 'target',  X.columns, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[var_significant]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos lista con los nombres de las columnas categóricas y numéricas por separado\n",
    "\n",
    "cat_cols = X.select_dtypes(include = ['object']).columns\n",
    "num_cols = X.select_dtypes(include = ['integer', 'float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir transformadores para columnas categóricas y numéricas\n",
    "\n",
    "transformadores = [\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = \"first\"), \n",
    "     cat_cols),  # OneHotEncoder para las columnas categoricas\n",
    "    ('scaler', StandardScaler(), num_cols)]  # StandardScaler para las columnas numéricas\n",
    "\n",
    "# ColumnTransformer facilita aplicar diferentes transformaciones segun la columna\n",
    "preprocesador = ColumnTransformer(transformadores)\n",
    "\n",
    "# Crear el pipeline completo con OneHotEncoder seguido de StandardScaler\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocesador', preprocesador)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el pipeline sobre el conjunto de datos de train y transformar los datos de train y test\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\": [5, 6, 7, 8],\n",
    "          \"min_samples_leaf\": [10, 15, 20]}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_cv = GridSearchCV(rf, params, cv=3, scoring = 'roc_auc')\n",
    "\n",
    "rf_cv.fit(X_train,y_train)\n",
    "\n",
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf =  RandomForestClassifier(**rf_cv.best_params_, random_state = 0)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_get_auc(rf, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CAROLINA_ILLERA_39446109M_ML",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
